# -*- coding: utf-8 -*-
"""Breast_Cancer_Resnet50

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cB63kV3xIWdcVrLW8QNOzhcITuWbwNQ4
"""

! pip install opendatasets

#==========================================
# import libraries
#==========================================

import warnings
warnings.filterwarnings('ignore')

import opendatasets as od
import os
import glob

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense,Dropout,GlobalAveragePooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau



#=============================================
# Step-2: Download Dataset
#=============================================
# Username chanchalsaha7
# key: 9ae140efdb070deb48f1b8effc11f3d5

od.download('https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images')

#===========================================
# Create DataFrame
# ==========================================

base_dir='/content/breast-histopathology-images'

pattern=os.path.join(base_dir,'**','*.png')
filepaths=glob.glob(pattern,recursive=True)

label=[ os.path.basename(os.path.dirname(fp)) for fp in filepaths ]

df=pd.DataFrame({
    'label':label,
    'path':filepaths
})

train_df,val_test_df=train_test_split(df,test_size=0.2,random_state=42,stratify=df['label'])
val_df,test_df=train_test_split(val_test_df,test_size=0.5,random_state=42,stratify=val_test_df['label'])

print(train_df.shape)
print(test_df.shape)
print(val_df.shape)

#-====================================================
# Data Augmentation + Normalization + Data Generator
##====================================================
BATCH_SIZE=16
IMG_SIZE=(50,50)
EPOCHS=5
SEED=42

Datagen=ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    fill_mode='nearest',
    horizontal_flip=True,
    vertical_flip=True
)

val_test_datagen=ImageDataGenerator(
    rescale=1./255
)

# Train Generator

train_gen=Datagen.flow_from_dataframe(
    train_df,
    target_size=IMG_SIZE,
    x_col='path',
    y_col='label',
    batch_size=BATCH_SIZE,
    seed=SEED,
    shuffle=True,
    class_mode='binary'
)

# Val Generator

val_gen=val_test_datagen.flow_from_dataframe(
    val_df,
    target_size=IMG_SIZE,
    x_col='path',
    y_col='label',
    batch_size=BATCH_SIZE,
    seed=SEED,
    shuffle=False,
    class_mode='binary'
)

# Test Generator

test_gen=val_test_datagen.flow_from_dataframe(
    test_df,
    target_size=IMG_SIZE,
    x_col='path',
    y_col='label',
    shuffle=False,
    batch_size=BATCH_SIZE,
    seed=SEED,
    class_mode='binary'
)

#========================================
# Transfer Learning Model (ResNet50)
#========================================

base_model= ResNet50(weights='imagenet',include_top=False,input_shape=IMG_SIZE+(3,))
base_model.trainable=False

model=Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.3),
    Dense(1,activation='sigmoid')
])

model.compile(
    optimizer=Adam(learning_rate= 1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

cb=[
    EarlyStopping(patience=3,restore_best_weights=True),
    ModelCheckpoint('best_model.h5',save_best_only=True)
]

#-------------------------------
# Train Frozen Model(Baseline)
#-------------------------------

history=model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=5,
    callbacks=cb
)

#----------------------------------
# Evaluation
#----------------------------------
loss,acc =model.evaluate(test_gen)
print(f'Test Accuracy: {acc*100:.2f}%')

# Confusion matrix
y_true=test_gen.classes
y_pred=(model.predict(test_gen)>0.5).astype('int32').flatten()

cm=confusion_matrix(y_true,y_pred)

plt.figure(figsize=(6,4))
sns.heatmap(cm,annot=True,fmt='d',xticklabels=['Non_IDC','IDC'],yticklabels=['Non_IDC','IDC'])
plt.xlabel('predicted')
plt.ylabel('True')
plt.show()


 # classification report
print(classification_report(y_true,y_pred,target_names=['Non_IDC','IDC']))

# Training & Validation Accuracy
plt.figure(figsize=(8,4))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training vs Validation Accuracy')
plt.legend()
plt.show()

# Training & Validation Loss
plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.show()

#--------------------------------
# Base model Unfreeze
#---------------------------------

base_model.trainable=True

# fine-tune only last 50 layers

for layer in base_model.layers[:-50]:
  layer.trainable=False

model.compile(
    optimizer=Adam(learning_rate=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

cb=[
    EarlyStopping(patience=5,restore_best_weights=True),
    ReduceLROnPlateau(factor=0.5,patience=3),
    ModelCheckpoint('fine_tuned_model.h5',save_best_only=True)
]

h2=model.fit(
    train_gen,
    validation_data=val_gen,
    callbacks=cb,
    epochs=7
)

# Evaluation
loss,acc =model.evaluate(test_gen)
print(f'Test Accuracy: {acc*100:.2f}%')

# Confusion matrix
y_true=test_gen.classes
y_pred=(model.predict(test_gen)>0.5).astype('int32').flatten()

cm=confusion_matrix(y_true,y_pred)

plt.figure(figsize=(6,4))
sns.heatmap(cm,annot=True,fmt='d',xticklabels=['Non_IDC','IDC'],yticklabels=['Non_IDC','IDC'])
plt.xlabel('predicted')
plt.ylabel('True')
plt.show()


 # classification report
print(classification_report(y_true,y_pred,target_names=['Non_IDC','IDC']))

from sklearn.metrics import roc_auc_score

y_prob = model.predict(test_gen).ravel()
print("ROC-AUC:", roc_auc_score(y_true, y_prob))



# Training & Validation Accuracy
plt.figure(figsize=(8,4))
plt.plot(h2.history['accuracy'], label='Train Accuracy')
plt.plot(h2.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training vs Validation Accuracy')
plt.legend()
plt.show()

# Training & Validation Loss
plt.figure(figsize=(8,4))
plt.plot(h2.history['loss'], label='Train Loss')
plt.plot(h2.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.show()

